{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manya87/spam_detector/blob/main/ML_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htikXYTPjO0V",
        "outputId": "ed36c3ae-7811-4f89-e7c5-99eb97e68568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-06 07:07:09--  https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 477907 (467K) [text/plain]\n",
            "Saving to: ‚Äòsms.tsv‚Äô\n",
            "\n",
            "\rsms.tsv               0%[                    ]       0  --.-KB/s               \rsms.tsv             100%[===================>] 466.71K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-11-06 07:07:09 (13.1 MB/s) - ‚Äòsms.tsv‚Äô saved [477907/477907]\n",
            "\n",
            "‚úÖ Environment setup complete. Dataset 'spam_data.csv' ready.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1. SETUP AND DATA ACQUISITION\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # Suppress minor warnings for clean output\n",
        "\n",
        "# --- Data Download (Colab specific) ---\n",
        "# Fetches the raw SMS Spam Collection dataset from a reliable source.\n",
        "# The file format is Tab-Separated Values (TSV).\n",
        "!wget -nc https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\n",
        "!mv sms.tsv spam_data.csv\n",
        "\n",
        "print(\"‚úÖ Environment setup complete. Dataset 'spam_data.csv' ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpVKKnpbjQyi",
        "outputId": "b8b6406f-2d66-4180-a93d-a78304428339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Dataset Shape: (5572, 2)\n",
            "  Label                                            Message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
            "\n",
            "Label Mapping: ['ham', 'spam'] -> [0 1]\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 2. DATA LOADING, CLEANING, AND PREPARATION\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. Load the Tab-Separated Data\n",
        "# The dataset is loaded without a header, specifying columns 0 and 1.\n",
        "data = pd.read_csv(\n",
        "    'spam_data.csv',\n",
        "    sep='\\t',\n",
        "    header=None,\n",
        "    encoding='latin-1',\n",
        "    names=['Label', 'Message']\n",
        ")\n",
        "\n",
        "# 2. Check and Prepare Data\n",
        "print(f\"Initial Dataset Shape: {data.shape}\")\n",
        "print(data.head())\n",
        "\n",
        "# 3. Label Encoding (Categorical to Numerical)\n",
        "# Why: ML algorithms require numerical input for the target variable (y).\n",
        "label_encoder = LabelEncoder()\n",
        "data['Target'] = label_encoder.fit_transform(data['Label'])\n",
        "\n",
        "# Display the mapping to understand the output: 0 or 1\n",
        "print(f\"\\nLabel Mapping: {list(label_encoder.classes_)} -> {label_encoder.transform(label_encoder.classes_)}\")\n",
        "\n",
        "# 4. Define Features (X) and Target (y)\n",
        "X = data['Message'] # The raw text messages\n",
        "y = data['Target']   # The numerical labels (0 or 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhvHNsIsjYMz",
        "outputId": "d234e8f1-94cf-4289-88b3-7198e23a9cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Split: Training=4457, Testing=1115\n",
            "‚úÖ Feature Engineering Complete (CountVectorizer).\n",
            "Total Vocabulary Size (Features): 7473\n",
            "Vectorized Training Data Shape: (4457, 7473)\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 3. FEATURE ENGINEERING (CountVectorizer) AND DATA SPLIT\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. Split Data into Training and Testing Sets\n",
        "# Why: To evaluate the model on unseen data. random_state ensures reproducible results.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Data Split: Training={len(X_train)}, Testing={len(X_test)}\")\n",
        "\n",
        "# 2. Initialize CountVectorizer (Bag-of-Words)\n",
        "# Why: Converts text into a matrix of word counts.\n",
        "# 'stop_words' is used to remove common, non-informative words like 'a', 'the', 'is'.\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "# 3. Fit and Transform Training Data\n",
        "# The .fit() step builds the vocabulary dictionary ONLY from the training data.\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# 4. Transform Testing Data\n",
        "# Use the *fitted* vocabulary from the training step to transform the test data.\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Feature Engineering Complete (CountVectorizer).\")\n",
        "print(f\"Total Vocabulary Size (Features): {len(vectorizer.get_feature_names_out())}\")\n",
        "print(f\"Vectorized Training Data Shape: {X_train_vectorized.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL_JGVcljgCI",
        "outputId": "b07b7651-786e-4ee2-dca3-34032e87344c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model Trained successfully using Multinomial Naive Bayes.\n",
            "\n",
            "--- Model Performance Metrics ---\n",
            "Overall Accuracy: 98.92%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Ham (0)       0.99      1.00      0.99       966\n",
            "    Spam (1)       0.97      0.95      0.96       149\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.98      0.97      0.98      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "                   Predicted Ham (0)   Predicted Spam (1)\n",
            "Actual Ham (0):      962                 4\n",
            "Actual Spam (1):     8                   141\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 4. MODEL TRAINING AND EVALUATION\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. Initialize and Train the Model\n",
        "# Why MultinomialNB: It's excellent for classification problems based on word counts.\n",
        "spam_classifier = MultinomialNB()\n",
        "spam_classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"‚úÖ Model Trained successfully using Multinomial Naive Bayes.\")\n",
        "\n",
        "# 2. Generate Predictions\n",
        "y_pred = spam_classifier.predict(X_test_vectorized)\n",
        "\n",
        "# 3. Evaluation Metrics\n",
        "print(\"\\n--- Model Performance Metrics ---\")\n",
        "\n",
        "# Overall Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Overall Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Classification Report (Detailing Precision/Recall for each class)\n",
        "target_labels = ['Ham (0)', 'Spam (1)']\n",
        "report = classification_report(y_test, y_pred, target_names=target_labels)\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "# Confusion Matrix (Visualizing Errors)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "# Custom print for better readability in a console/colab output\n",
        "print(\"                   Predicted Ham (0)   Predicted Spam (1)\")\n",
        "print(f\"Actual Ham (0):      {cm[0][0]:<17}   {cm[0][1]}\")\n",
        "print(f\"Actual Spam (1):     {cm[1][0]:<17}   {cm[1][1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSyLzN3pjmDo",
        "outputId": "f69099b2-85be-44ed-8682-172a1e321186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "      üìß INTERACTIVE SPAM DETECTION TOOL üìß\n",
            "==================================================\n",
            "Type 'exit' or 'quit' to stop the prediction tool.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 5. DEPLOYABLE PREDICTION FUNCTION (INTERACTIVE)\n",
        "# ==============================================================================\n",
        "\n",
        "# Note: This function relies on the 'vectorizer' and 'spam_classifier' variables\n",
        "# defined and trained in the previous cells.\n",
        "\n",
        "def spam_predictor(email_message: str) -> str:\n",
        "    \"\"\"\n",
        "    Takes a raw string email message, processes it using the trained vectorizer,\n",
        "    and returns a clean 'Spam' or 'Ham' classification using the trained model.\n",
        "    \"\"\"\n",
        "    # Step 1: Prepare the input (wrap the string in a list)\n",
        "    input_list = [email_message]\n",
        "\n",
        "    # Step 2: Transform the input using the FITTED vectorizer\n",
        "    input_vectorized = vectorizer.transform(input_list)\n",
        "\n",
        "    # Step 3: Get the numerical prediction from the trained classifier\n",
        "    # [0] is used to extract the single prediction from the returned array\n",
        "    numerical_prediction = spam_classifier.predict(input_vectorized)[0]\n",
        "\n",
        "    # Step 4: Return the human-readable label\n",
        "    if numerical_prediction == 0:\n",
        "        return \"‚û°Ô∏è NOT SPAM (Ham)\"\n",
        "    else:\n",
        "        return \"‚ùå SPAM\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"      üìß INTERACTIVE SPAM DETECTION TOOL üìß\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Type 'exit' or 'quit' to stop the prediction tool.\")\n",
        "\n",
        "    while True:\n",
        "        # Prompt user for input\n",
        "        user_input = input(\"\\nPaste your email or message here: \")\n",
        "\n",
        "        # Check for exit command\n",
        "        if user_input.lower() in ['exit', 'quit']:\n",
        "            print(\"\\nShutting down the predictor. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Ensure the user actually entered something\n",
        "        if not user_input.strip():\n",
        "            print(\"Please enter a message to classify.\")\n",
        "            continue\n",
        "\n",
        "        # Get and display the prediction\n",
        "        try:\n",
        "            prediction = spam_predictor(user_input)\n",
        "            print(f\"\\nModel Classification: {prediction}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nAn error occurred during prediction: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sE6Z9LSW9zD5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVACaB51PA5jW69LMQbjER",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}